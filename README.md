<div align="center">
  <img src="https://user-images.githubusercontent.com/44631215/80526256-7015cf80-89cd-11ea-8ffa-ad0234451773.PNG">
</div>
<br><br><br>


[![Python](https://img.shields.io/pypi/pyversions/tensorflow.svg?style=plastic)](https://badge.fury.io/py/tensorflow)
<a href="https://opencv.org/"><img alt="openCV" src="https://img.shields.io/badge/OpenCV-4.3.0-red.svg"/></a>
<a href="https://www.djangoproject.com/"><img alt="django" src="https://img.shields.io/badge/django-3.0-green.svg"/></a>
  <a href="https://www.djangoproject.com/"><img alt="djangorestframework" src="https://img.shields.io/badge/djangorestframework-3.10.3-brightgreen.svg?style=flat"/></a>
  
##Motivation
<p>With the recent development of the Internet and streaming services, more Internet lectures are being created, and demand is also increasing.
However, these Internet lectures continue to have a similar system, and there are still things that cause discomfort by listening in the system.
First, the Internet lecture is a structure in which the lecturer and the viewer cannot interact.
Viewers have a hard time knowing where they haven't seen if they haven't focused on the lecture.
Even video providers can't tell which part of their video wasn't responding well and where the viewers had a good concentration rate.
So, we developed a READ solution, Reaction evaluation & aggregation data, to solve this problem.
It is a process divided into Reaction evaluation part that judges user's concentration and Aggregation data part that collects viewer's data and analyzes it to give feedback to video providers.
Through this solution, video viewers can analyze the concentration level of the video to compensate for the lack of concentration and provide motivation to increase concentration.
Video providers can also see the concentration of viewers, grasp the strengths and weaknesses of their video, and make efforts to improve the video.
  </p>
